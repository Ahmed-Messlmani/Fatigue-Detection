{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pcd with vgg16.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNMOVBl8rQCSK1wWDTC08Q0"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"rJqnj5ObPAuT","colab":{"base_uri":"https://localhost:8080/","height":67},"executionInfo":{"status":"ok","timestamp":1590761680826,"user_tz":-120,"elapsed":10283,"user":{"displayName":"ahmed messlmani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguLdvut6KI6LOzv6X6i49DpEeaqn75PEZ-eKEk=s64","userId":"17814274648723543715"}},"outputId":"f6a70e29-4c19-465a-c784-85b0300a69c1"},"source":["from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers.pooling import AveragePooling2D\n","from keras.applications import VGG16\n","from keras.layers.core import Dropout\n","from keras.layers.core import Flatten\n","from keras.layers.core import Dense\n","from keras.layers import Input\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.utils import np_utils\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","from imutils import paths\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import cv2\n","import os\n","# load model without classifier layers\n","baseModel = VGG16(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(300, 300, 3)))\n","headModel = baseModel.output\n","headModel = AveragePooling2D(pool_size=(4, 4))(headModel)\n","headModel = Flatten(name=\"flatten\")(headModel)\n","headModel = Dense(128, activation=\"relu\")(headModel)\n","headModel = Dropout(0.5)(headModel)\n","headModel = Dense(2, activation=\"softmax\")(headModel)\n","model = Model(inputs=baseModel.input, outputs=headModel)\n","for layer in baseModel.layers:\n","\tlayer.trainable = False"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58892288/58889256 [==============================] - 5s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"b4AR5L3-PeN4"},"source":["INIT_LR = 1e-4\n","EPOCHS = 20\n","BS = 128\n","opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n","model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n","\tmetrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BhlsPFicPir7","colab":{"base_uri":"https://localhost:8080/","height":168},"executionInfo":{"status":"ok","timestamp":1590761808620,"user_tz":-120,"elapsed":117036,"user":{"displayName":"ahmed messlmani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguLdvut6KI6LOzv6X6i49DpEeaqn75PEZ-eKEk=s64","userId":"17814274648723543715"}},"outputId":"36a0d61e-4ec0-462e-982c-f154282c47e2"},"source":["from imutils import paths\n","from keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import argparse\n","import os\n","root_path = r'/content/drive/My Drive/dataset1'\n","\n","train_dir = os.path.join(root_path, 'train')\n","validation_dir = os.path.join(root_path, 'validation')\n","\n","train_fat_dir = os.path.join(train_dir, 'fatigue')  # directory with our training fat pictures\n","train_nofat_dir = os.path.join(train_dir, 'non fatigue')  # directory with our training nofat pictures\n","validation_fat_dir = os.path.join(validation_dir, 'fatigue')  # directory with our validation fat pictures\n","validation_nofat_dir = os.path.join(validation_dir, 'non fatigue')  # directory with our validation nofat pictures\n","\n","num_fat_tr = len(os.listdir(train_fat_dir))\n","num_nofat_tr = len(os.listdir(train_nofat_dir))\n","\n","num_fat_val = len(os.listdir(validation_fat_dir))\n","num_nofat_val = len(os.listdir(validation_nofat_dir))\n","\n","total_train = num_fat_tr + num_nofat_tr\n","total_val = num_fat_val + num_nofat_val\n","\n","print('total training fat images:', num_fat_tr)\n","print('total training nofat images:', num_nofat_tr)\n","\n","print('total validation fat images:', num_fat_val)\n","print('total validation nofat images:', num_nofat_val)\n","print(\"--\")\n","print(\"Total training images:\", total_train)\n","print(\"Total validation images:\", total_val)\n","\n","train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data\n","validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data\n","\n","# Flow training images in batches of 20 using train_datagen generator\n","train_generator = train_image_generator.flow_from_directory(train_dir,\n","                                                    batch_size = 128,\n","                                                     \n","                                                    target_size = (300, 300))     \n","\n","# Flow validation images in batches of 20 using test_datagen generator\n","validation_generator =  validation_image_generator.flow_from_directory( validation_dir,\n","                                                          batch_size  = 128,\n","\n","\n","                                                          target_size = (300,300))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total training fat images: 3719\n","total training nofat images: 9200\n","total validation fat images: 718\n","total validation nofat images: 2162\n","--\n","Total training images: 12919\n","Total validation images: 2880\n","Found 12919 images belonging to 2 classes.\n","Found 2880 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SHzl6h7WQAIW","colab":{"base_uri":"https://localhost:8080/","height":185},"outputId":"0b708302-ae6b-46b4-d14f-91362cac0b23"},"source":["history = model.fit(\n","            train_generator,\n","            validation_data = validation_generator,\n","            steps_per_epoch = total_train // 128,\n","            epochs = 20,\n","            validation_steps = total_val // 128)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py:616: UserWarning: The input 20 could not be retrieved. It could be because a worker has died.\n","  UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["100/100 [==============================] - 13526s 135s/step - loss: 0.5637 - accuracy: 0.7163 - val_loss: 0.5072 - val_accuracy: 0.7475\n","Epoch 2/20\n","100/100 [==============================] - 13411s 134s/step - loss: 0.4510 - accuracy: 0.7914 - val_loss: 0.4336 - val_accuracy: 0.7311\n","Epoch 3/20\n","100/100 [==============================] - 13699s 137s/step - loss: 0.3959 - accuracy: 0.8309 - val_loss: 0.5366 - val_accuracy: 0.7384\n","Epoch 4/20\n"," 18/100 [====>.........................] - ETA: 2:36:11 - loss: 0.3558 - accuracy: 0.8585"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y_1BiEE2QMDw","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1590761654289,"user_tz":-120,"elapsed":35813,"user":{"displayName":"ahmed messlmani","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GguLdvut6KI6LOzv6X6i49DpEeaqn75PEZ-eKEk=s64","userId":"17814274648723543715"}},"outputId":"c47391f6-52aa-4ce7-c18b-38aacdfa9dc3"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oi9qkOqZx_v2"},"source":[""],"execution_count":null,"outputs":[]}]}